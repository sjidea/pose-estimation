{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import torchvision.transforms as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('/openpose')\n",
    "from model import PoseEstimationWithMobileNet, example\n",
    "from include import CocoKeypoints\n",
    "import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10000\n",
    "lr = 1e-3\n",
    "batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PoseEstimationWithMobileNet()\n",
    "model = nn.DataParallel(model).to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr = lr, weight_decay= 1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "        transforms.Normalize(),\n",
    "        transforms.RandomApply(transforms.HFlip(), 0.5),\n",
    "        transforms.RescaleRelative(),\n",
    "        transforms.Crop(368),\n",
    "        transforms.CenterPad(368),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.44s)\n",
      "creating index...\n",
      "index created!\n",
      "filter for keypoint annotations ...\n",
      "... done.\n",
      "Images: 250\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/var/lib/docker/openpose/coco\"\n",
    "ann_train_dir = [os.path.join(data_dir, 'annotations', item) \n",
    "                 for item in ['person_keypoints_val2017.json']]\n",
    "ann_val_dir = os.path.join(data_dir, 'images/val2017')\n",
    "\n",
    "image_transform = None\n",
    "n_train = 200\n",
    "n_val = 50\n",
    "datas = [CocoKeypoints(\n",
    "            root=ann_val_dir,\n",
    "            annFile=item,\n",
    "            preprocess=preprocess,\n",
    "            image_transform=image_transform,\n",
    "            target_transforms=image_transform, \n",
    "            n_images = n_train+n_val,\n",
    "        ) for item in ann_train_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = datas[0]\n",
    "# (image, heatmaps, pafs), filepath = data[0]\n",
    "# # print(f\"Shape of original image = {im.shape}\")\n",
    "# # print(f\"Shape of heatmap = {heatmap.shape}\")\n",
    "# # print(f\"Shape of paf = {paf.shape}\")\n",
    "\n",
    "# # reference image\n",
    "# fig = plt.figure()\n",
    "# ref_image = Image.open(filepath)\n",
    "# plt.imshow(ref_image)\n",
    "\n",
    "# # image from dataloader\n",
    "# im = image.numpy()\n",
    "# im = np.transpose(im, (1, 2, 0))\n",
    "# max_value_i = np.max(im)\n",
    "# min_value_i = np.min(im)\n",
    "# print(f\"max:{max_value_i}, min:{min_value_i}\")\n",
    "# n_im = (im - min_value_i)/(max_value_i-min_value_i)\n",
    "# fig = plt.figure()\n",
    "# plt.imshow(n_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# heatmap = heatmaps.numpy()\n",
    "# heatmap = np.transpose(heatmap, (1, 2, 0))\n",
    "# heatmap = cv2.resize(heatmap, (0, 0), fx=8, fy=8, interpolation=cv2.INTER_CUBIC)\n",
    "# max_value = np.max(heatmap)\n",
    "# min_value = np.min(heatmap)\n",
    "\n",
    "# fig = plt.figure(figsize = (50, 24))\n",
    "# im_ = Image.fromarray(im.astype(np.uint8)*255)\n",
    "# im_ = im_.convert('RGB')\n",
    "# label = ['nose', 'neck', 'Rsho', 'Relb', 'Rwri', 'Lsho', 'Lelb', 'Lwri', 'Rhip', \n",
    "#          'Rkne', 'Rank', 'Lhip', 'Lkne', 'Lank', 'Leye', 'Reye', 'Lear', 'Rear', 'pt19'] \n",
    "# for i in range(18):\n",
    "#     vis_img = (heatmap[:, :, i]-min_value)/max_value\n",
    "#     vis_img = Image.fromarray(np.uint8(cm.jet(vis_img) * 255))\n",
    "#     vis_img = vis_img.convert('RGB') \n",
    "#     vis_img = Image.blend(im_, vis_img, 0.5)\n",
    "#     vis_img = np.array(vis_img)\n",
    "#     plt.subplot(3,6,i+1)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.grid(False)\n",
    "#     plt.imshow(vis_img)\n",
    "#     plt.xlabel(label[i], fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paf = pafs.numpy()\n",
    "# paf = np.transpose(paf, (1, 2, 0))\n",
    "# paf = cv2.resize(paf, (0, 0), fx=8, fy=8, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# fig = plt.figure(figsize = (50, 24))\n",
    "# max_value = np.max(paf)\n",
    "# min_value = np.min(paf)\n",
    "# for i in range(19):\n",
    "#     vis_img_x = (paf[:, :, i*2]-min_value)/max_value \n",
    "#     vis_img_y = (paf[:, :, i*2+1]-min_value)/max_value /255   \n",
    "#     plt.subplot(3,7,i+1)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.grid(False)\n",
    "#     plt.imshow(im, interpolation='nearest')\n",
    "#     plt.imshow(vis_img_x, cmap=plt.cm.jet, alpha=0.3)\n",
    "#     plt.imshow(vis_img_y, cmap=plt.cm.jet, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model, image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.ConcatDataset(datas)\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(dataset, (n_train, n_val))\n",
    " \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            train_data, \n",
    "            batch_size = batch, \n",
    "            shuffle = True,\n",
    "            num_workers = 8,\n",
    "            drop_last = True,\n",
    "            )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "            val_data, \n",
    "            batch_size = batch,\n",
    "            shuffle = True,\n",
    "            num_workers = 8,\n",
    "            drop_last = True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6004 (pid 24070), started 13:14:38 ago. (Use '!kill 24070' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-53438120fe92d290\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-53438120fe92d290\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6004;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "log_dir = '/openpose/runs/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "summary = SummaryWriter('/openpose/runs')\n",
    "%tensorboard --logdir /openpose/runs --port 6004 --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cfbc320e53f49b88b8258df17d00808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "you can only change requires_grad flags of leaf variables.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c231b81904fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#         train_tot_loss += paf_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrain_tot_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpafs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtrain_tot_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mtrain_tot_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you can only change requires_grad flags of leaf variables."
     ]
    }
   ],
   "source": [
    "ti = time.time()\n",
    "save_dir = \"./best_model\"\n",
    "best_val_loss = np.inf\n",
    "for epoch in tqdm(range(n_epoch)):    \n",
    "    train_tot_loss = 0\n",
    "    val_tot_loss = 0\n",
    "    ######### TRAIN ########\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for i, ((images, heatmaps, pafs), _) in enumerate(train_loader):\n",
    "        i = i+1\n",
    "        images = images.to(device)\n",
    "        heatmaps = heatmaps.to(device)\n",
    "        pafs = pafs.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        stages_output = model(images)\n",
    "        paf = stages_output[-1]\n",
    "        heatmap = stages_output[-2]\n",
    "    \n",
    "#         hm_loss = criterion(heatmaps, heatmap)\n",
    "#         paf_loss = criterion(pafs, paf)\n",
    "#         train_tot_loss += hm_loss\n",
    "#         train_tot_loss += paf_loss\n",
    "        train_tot_loss = criterion(heatmaps, heatmap) + criterion(pafs, paf)\n",
    "        train_tot_loss.requires_grad = True\n",
    "        train_tot_loss.backward()\n",
    "        \n",
    "        print(f\"tot_loss: {train_tot_loss}\")\n",
    "        optimizer.step()\n",
    "        \n",
    "    summary.add_scalar('train_loss', train_tot_loss, epoch)\n",
    "\n",
    "#     ######## VALIDATION ########\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        i=0\n",
    "        for i, ((images, heatmaps, pafs), filepath) in enumerate(val_loader):\n",
    "            i = i+1\n",
    "            images = images.to(device)\n",
    "            heatmaps = heatmaps.to(device)\n",
    "            pafs = pafs.to(device)\n",
    "            \n",
    "            stages_output = model(images)\n",
    "            paf = stages_output[-1].to(device=device, dtype=torch.long)\n",
    "            heatmap = stages_output[-2].to(device=device, dtype=torch.long)\n",
    "            \n",
    "            val_loss = criterion(heatmaps, heatmap) + criterion(pafs, paf)\n",
    "            val_tot_loss += val_loss\n",
    "            \n",
    "    scheduler.step(val_tot_loss)\n",
    "    summary.add_scalar('val_loss', val_tot_loss, epoch)    \n",
    "    if val_tot_loss<best_val_loss:\n",
    "        torch.save(model.state_dict(), save_dir)\n",
    "   \n",
    "    # print status every 10 epoch\n",
    "    if epoch % 10 == 0 or epoch == n_epoch-1:\n",
    "        ti2 = time.time()\n",
    "        ti_ = ti2-ti\n",
    "        for param in optimizer.param_groups:\n",
    "            print(f\"for {epoch} epoch, {int(ti_/60)}min {int(ti_%60)}sec elapsed, lr = {param['lr']}\")\n",
    "\n",
    "# summary.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_samples(self, z, y=None):\n",
    "#         self.generator.eval()\n",
    "#         batch_size = z.size(0)\n",
    "#         # Parse y\n",
    "#         if y is None:\n",
    "#             y = self.ydist.sample((batch_size,))\n",
    "#         elif isinstance(y, int):\n",
    "#             y = torch.full((batch_size,), y,\n",
    "#                            device=self.device, dtype=torch.int64)\n",
    "#         # Sample x\n",
    "#         with torch.no_grad():\n",
    "#             x = self.generator(z, y)\n",
    "#         return x\n",
    "\n",
    "    \n",
    "    \n",
    "#         outdir = os.path.join(self.img_dir, class_name)\n",
    "#         if not os.path.exists(outdir):\n",
    "#             os.makedirs(outdir)\n",
    "#         outfile = os.path.join(outdir, '%08d.png' % it)\n",
    "\n",
    "#         imgs = imgs / 2 + 0.5\n",
    "#         imgs = torchvision.utils.make_grid(imgs)\n",
    "#         torchvision.utils.save_image(imgs, outfile, nrow=8)\n",
    "\n",
    "#         if self.monitoring == 'tensorboard':\n",
    "#             self.tb.add_image(class_name, imgs, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    heatmap = heatmaps[0]\n",
    "    device2 = torch.device(\"cpu\")\n",
    "    heatmap = heatmap.to(device2)\n",
    "    heatmap = heatmap.detach()\n",
    "    heatmap = heatmap.numpy()\n",
    "    \n",
    "    heatmap = np.transpose(heatmap, (1, 2, 0)) # (46, 46, 19)\n",
    "#     heatmap = cv2.resize(heatmap, (0, 0), fx=8, fy=8, interpolation=cv2.INTER_CUBIC)\n",
    "    max_value = np.max(heatmap)\n",
    "    min_value = np.min(heatmap)\n",
    "    label = ['nose', 'neck', 'Rsho', 'Relb', 'Rwri', 'Lsho', 'Lelb', 'Lwri', 'Rhip', \n",
    "             'Rkne', 'Rank', 'Lhip', 'Lkne', 'Lank', 'Leye', 'Reye', 'Lear', 'Rear', 'pt19'] \n",
    "    for i in range(18):\n",
    "        vis_img = (heatmap[:, :, i]-min_value)/max_value\n",
    "        vis_img = Image.fromarray(np.uint8(cm.jet(vis_img) * 255))\n",
    "        vis_img = vis_img.convert('RGB')  \n",
    "        vis_img = np.array(vis_img) #(46, 46, 3)\n",
    "#         vis_img = np.transpose(heatmap, (2, 0, 1))\n",
    "#         summary.add_image('ground truth', vis_img)\n",
    "#         print(vis_img.shape)\n",
    "#         if i == 0:\n",
    "#             vis = vis_img\n",
    "#         else:\n",
    "#             vis = np.concatenate((vis, vis_img), axis=-1)\n",
    "#         print(f\"{vis.shape} of epoch\")\n",
    "#     vis = np.reshape(vis, (46, 46, 3, 18))\n",
    "#     vis = np.transpose(vis, (2, 0, 1, 3))\n",
    "    \n",
    "#     summary.add_image('ground truth', vis, max_outputs=18, step = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
